%================================================================
% SLO
%----------------------------------------------------------------
% datoteka: 	thesis_template.tex
%
% opis: 		predloga za pisanje diplomskega dela v formatu LaTeX na
% 				Univerza v Ljubljani, Fakulteti za računalništvo in informatiko
%
% pripravili: 	Matej Kristan, Zoran Bosnić, Andrej Čopar,
%			  	po začetni predlogi Gašperja Fijavža
%
% popravil: 	Domen Rački, Jaka Cikač, Matej Kristan
%
% verzija: 		30. september 2016 (dodan razširjeni povzetek)
%================================================================


%================================================================
% SLO: definiraj strukturo dokumenta
% ENG: define file structure
%================================================================
\documentclass[a4paper, 12pt]{book}
\usepackage{longtable}

%================================================================
% SLO: Odkomentiraj "\SLOtrue " za izbiro slovenskega jezika
% ENG: Uncomment "\SLOfalse" to chose English languagge
%================================================================
\newif\ifSLO
% switch language

\SLOtrue % Enables Slovenian language
%\SLOfalse  % Enables English language

%================================================================
% SLO: vključi oblikovanje in pakete
% ENG: include design and packages
%================================================================
\input{style/thesis_style}

%----------------------------------------------------------------
% |||||||||||||||||||||| USTREZNO POPRAVI |||||||||||||||||||||||
% |||||||||||||||||||||| EDIT ACCORDINGLY |||||||||||||||||||||||
%----------------------------------------------------------------
\newcommand{\ttitle}{Barvanje črnobelih slik z globokimi modeli}
\newcommand{\ttitleEn}{Deep models for image coloring}
\newcommand{\tsubject}{\ttitle}
\newcommand{\tsubjectEn}{\ttitleEn}
\newcommand{\tauthor}{Primož Godec}
\newcommand{\temail}{p.godec9@gmail.com}
\newcommand{\myyear}{2017}
\newcommand{\tkeywords}{Umetna inteligenca, Odkiravanje znanj iz podatkov, globoko učenje, nevronske mreže}
\newcommand{\tkeywordsEn}{Artificial inteligence, data mining, deep learning, neural networks}
\newcommand{\mysupervisor}{prof.~dr.~Blaž Zupan}
\newcommand{\mycosupervisor}{}

% include formatted front pages
\input{style/thesis_front_pages}

%================================================================
% ENG: main pages of the thesis
%================================================================

%----------------------------------------------------------------
% Poglavje (Chapter) 1: Uvod
%----------------------------------------------------------------
\chapter{Uvod}
\label{ch:uvod}

Čeprav se so prvo barvno fotografijo naredili že leta 1886 \cite{ARCHAMBAULT}, se je barvna fotografija v vsakdanji uporabi uveljavila šele mnogo kasneje. Tako imajo naši stari starši še vedno veliko črno belih fotografij. Ker te prikazujejo realnost povsem drugače, bi jih radi obarvali. Pa je to sploh mogoče?

\begin{figure}
\begin{center}
\includegraphics[width=12cm]{imcompare}
\end{center}
\caption{Algoritem za vhod vzame črno-belo (sivinsko) sliko, preko nivojev nevronske mreže določi barvne komponente in za konec združi sivinsko sliko z barvnimi komponentami.}
\label{im:compare}
\end{figure}

Ta problem rešujejo algoritmi za barvanje črno-belih slik. Ti dobijo kot vhod črno-belo fotografijo, ki ji na to dodajo barvo, kot je prikazano na sliki \ref{im:compare}. Algoritmi za barvanje črno-belih slik se uporabljajo na več področjih: barvanje starih slik, barvanje črno-belih filmov in v pomoč pri umetnosti. 
Za človeka je barvanje črno-belih slik, ki so prikazane na sliki \ref{im:pari-cb-b}, enostavna naloga. Z vsakdanjim opazovanjem sveta se je človek naučil, da je nebo modro z belimi oblaki, drevesa so zelena in cesta je siva. Za objekte, ki nimajo enolično določene barve ljudje lahko ugibamo kakšne barve naj bi predmet bil. Pri tem opravilu je potrebno veliko razumevanja, saj iz sivinskih slik ni možno direktno razbrati barv, namreč pri nastanku sivinske slike se veliko informacij izgubi (dve od treh dimenzij).

\begin{figure}
\begin{center}
\includegraphics[width=13cm]{black-colored-comparison}
\end{center}
\caption{Primeri barvanja črno-belih slik. Barvanje je bilo izvedeno z algoritmi, ki so bili razviti v okviru te magistrske naloge. Za vsako sliko je prikazana črno-bela slika, ki je bila vhod v algoritem in obarvana slika - izhod algoritma. }
\label{im:pari-cb-b}
\end{figure}

Problem postane bolj kompleksen, ko ga želimo rešiti na avtomatski način z računalnikom. Pri tem nam je v pomoč dejstvo, da je možno iz tekstur objektov te prepoznati in jim na ta način določiti njihovo barvo. Pri objektih, ki nimajo enolično določeno barv (na primer avtomobili, stavbe in knjige) je izziv še mnogo težji. Pri tem nam delo olajša dejstvo, da ne želimo, da slika zgleda enaka originalni ampak, da ta zgleda naravno. Nihče ne bo vedel, da je avtomobil, ki smo ga pobarvali rumeno bil v resnici rdeče barve. 

Pri barvanju slik algoritmu, ki je zasnovan na podlagi nevronskih mrež,  podamo sivinsko sliko ($L$ kanal barvnega prostora \textit{CIE Lab}), sistem pa vrne $a$ in $b$ kanal v istem barvnem prostoru. Za treniranje modela potrebujemo veliko količino črno-belih slik z referenčno barvno sliko, kar je praktično zastonj na voljo na spletu. Za treniranje lahko vzamemo katerokoli sliko, jo pretvorimo v barvni prostor \textit{CIE Lab}, kjer $L$ kanal predstavlja sivinsko sliko. 

V tej magistrski nalogi rešujemo problem barvanja črno-belih slik in videov z večimi različnimi implementacijami. Za začetek smo implementirali več algoritmov za barvanje črno-belih slik. Rezultate smo med seboj primerjali s računanjem razlike med obarvano in originalno sliko. Rezultate smo primerjali tudi z dvema implementacijama iz sorodnih del. Ker pa obstaja veliko objektov, ki nimajo enolične barve (avtomobili, zgradbe, ...) in naš namen ni doseči enakega barvanja, vendar takega, ki da naravne rezultate, smo barvanje slik ocenjevali s pomočjo uporabnikov. V spletni anketi smo uporabnike spraševali katera slika je bolj naravno obarvana (originalna ali slika obarvana z algoritmom).

Kasneje smo se odločili poskusiti tudi barvanja vida. Za barvanje smo arhitekturo nevronske mreže, ki je najbolje delovala na slikah prilagodili še za video. 

%----------------------------------------------------------------
% Poglavje (Chapter) 2: Pregled področja
%----------------------------------------------------------------
\chapter{Pregled Področja}
\label{ch:pregled}

\section{Predstavitev slikovnih podatkov in barvni prostori}
\label{se:podatki}

Slike, ki jih uporabljamo za učenje so shranjene v \textit{RGB} \cite{Pm2013} barvnem prostoru. Kot je pokazano v \cite{Iizuka2016} se izkaže, da prostor RGB ni direktno primeren za učenje algoritmov za barvanje iz dveh razlogov:

\begin{itemize}

\item \textbf{Sistem se ne ujema dobro s človeško percepcijo barv}, saj so razdalje med enako sorodnimi barvami različne glede na odtenek \cite{Prangnell}. Na primer, če imamo dva para barv rdečo in svetlo rdečo, ter modro in svetlo modro, pri čemer sta barvi v vsakem paru za človekov vizualni sistem enako različni, sta razdalji v RGB barvnem prostoru različni . 

\item \textbf{Nima ločenega kanala za svetlost} \cite{Pm2013}. Glede na to, da modeli za barvanje napovedujejo le barvne elemente v sliki, svetlost pa se vzame iz originalne slike, je najbolj priročno, če uporabljamo barvni prostor, ki ima ločen kanal za svetlost. 

\end{itemize}

\subsection{Izbira primernega barvnega prostora}

Na podlagi teh predpostavk je izbira prostorov omejena na \textit{Lab} \cite{Bansal}, \textit{YUV} \cite{Jack2005} in \textit{HSL} \cite{Pm2013}. Vsi ustrezajo drugi predpostavki iz \ref{se:podatki}. Edini, ki zares ustreza prvi predpostavki je \textit{Lab}. Iz ugotovitev iz sorodnih del \cite{Iizuka2016, Zhang2016, Larsson2016} se tudi najbolje izkaže prostor \textit{CIE L*a*b}.

Obstaja več verzij barvnega prostora \textit{Lab}, vendar se trenutno najbolj uporablja \textit{CIE L*a*b*}, ki naj bi bil najboljša aproksimacija človeškega vizualnega sistema \cite{Prangnell}. Prostor ima to prednost, da je neodvisen od naprave. 
Prostor CIE L*a*b* predstavi vse barve, ki jih je možno zaznati z tremi barvnimi kanali. $L*$ predstavlja svetlost, $a*$ se razširja od zelene proti rdeči barvi in $b*$ od modre proti rumeni. $L*$ ser razteza od 0, ki predstavlja črno barvo, do 100, ki predstavlja belo barvo \cite{Weatherall1992}. Prostor je grafično prikazan na sliki \ref{img:lab} $a*$ in $b*$ komponenti nimata uradne omejitve, vendar sta v implementacijah ponavadi omejene na vrednosti v intervalu $[-128, 127]$, kar je možno predstaviti z 8 bitnim celim številom \cite{Everding}. Ker zaradi pretvorb iz barvnega prostora \textit{RGB} vrednosti višje od $100$ ali nižje $-100$ redko dosežemo smo opazili, da nekatere implementacije omejijo barvni prostor na interval $[-100, 100]$. Za pomoč pri implementaciji nevronske mreže smo sami preizkusili kakšen je dejanski interval barv pretvorjenih iz \textit{RGB} barvnega prostora. Intervale si lahko pogledate v tabeli \ref{tab:rgbcie}.

\begin{figure}
\begin{center}
\includegraphics[width=6cm]{cielab}

\end{center}
\caption{Slika prikazuje kanale barvnega prostora CIE L*a*b*. L* predstavlja svetlost, a* se razteza od zelene barve v najbolj negativni točki proti rdeči barvi, b* ser razteza od modre proti rumeni. Nasprotujoče barve na kanalih a* in b* se nikoli ne kombinirajo v odtenek. Iz: Adobe, Technical Guid, CIELAB, \url{http://dba.med.sc.edu/price/irf/Adobe_tg/models/cielab.html} (dostopano: 24. junij 2017)}
\label{nn-structure}
\end{figure}

\begin{table}
\caption{Njavečje in njmanjše vrednosti posamezne komponente CIE L*a*b* barvnega prostora, pri pretvorbi vseh barv iz barvnega prostora RGB. Pretvorba je bila narejena z uporabo osvetlitve $D65$, ki določa temperaturo bele točke. }
\begin{center}
    \begin{tabular}{l|ccc}
        Kanal & Najmanjša vrednost & Največja vrednost \\
        \hline
        L* & 0 & 100 \\
        a* & -86.185 & 98,254 \\
        b* & -107.863 & 94.482 \\
    \end{tabular}
\end{center}
\label{tab:rgbcie}
\end{table}

\subsection{Pretvarjanje med RGB in CIE L*a*b* barvnim prostorom}

Za pretvorbo med prostoroma ni enostavne enačbe, saj je \textit{RGB} barvni prostor odvisen od naprav, \textit{CIE L*a*b*} pa ne. Tako se pretvorba zgodi v treh korakih \cite{Connolly1997}: 

\begin{enumerate}

\item \textbf{Pretvorba iz RGB v sRGB ali Adobe RGB}, saj sta ta barvna prostora neodvisna od naprave. Ta pretvorba je odvisna od naprave. Slike, ki jih bomo uporabili v našem delu so že v sRGB obliki, saj so bile pretvorjene, ko so bile zajete z fotoaparatom.

\item \textbf{Pretvorba CIE 1931 barvni prostor} ali drugače imenovan XYZ barni prostor. Ta pretvorba se izvede s pomočjo linearne pretvorbe z matriko. Matrika je odvisna od izibire referenčne bele barve. Običajno se izbere referenčno temperaturo belo točke \textit{D65}, ki je tudi standardizirana\footnotemark \cite{Ohta2005}.

\footnotetext{Zapis na uradni strani komisije International Commision on Illumination (krajše CIE), ki je postavila standard: \url{http://cie.co.at/index.php?i_ca_id=484}}

\item \textbf{Pretvorba iz XYZ v L*a*b*} se izvede po enačbah opisanih v \cite{Schwiegerling2004}.  % če je potrebno jih lahko prepišem

\end{enumerate}

\section{Obstoječe metode za barvanje črno-belih slik}

Metode za barvanje črno-belih slik delimo v dve večji skupini. Prva zahteva interakcijo uporabnika, pri drugi pa barvanje poteka popolnoma avtomatsko.

\subsection{Metode, ki zahtevajo interakcijo uporabnika}

To skupion metod delimo na tehnike, ki temeljijo na uporabnikovem barvanju manjših delov slik (ang. {\em scribble based}) \cite{levin2004colorization, huang2005adaptive} in tiste, ki temeljijo na primerih (ang. {\em example based}) \cite{Koleini2010, shirley2001color, tai2005local}. Pri prvih uporabnik določi barvo določenih točk v sliki, te pa algoritem avtomatsko razširi preko cele slike. Pri barvanju na primerih pa mora uporabnik izbrati sliko, ki je podobna tisti, ki jo želimo pobarvati, algoritem nato lastnosti izbrane slike razširi na drugo sliko ali množico slik. Tehnika barvanja s primeri se uporablja za barvanje videov, saj je v tem primeru potrebno ročno pobarvati na primer vsako stoto sliko, na ostale pa algoritem sam razširi lastnosti ročno barvane slike. 

\subsection{Popolnoma avtomatske metode}

V magistrskem delu se osredotočamo na avtomatske metode barvanja. To so algoritmi, ki samostojno, brez uporabnikovega posredovanja, obarvajo celotno sliko. Prvi dve metodi, ki sta bili predlagani na tem področju, temeljita na značilkah (ang. {\em features}) pridobljenih iz slike. Tukaj gre predvsem za značilke, ki opisujejo intenziteto posamezne barve in opisnike, ki opisujejo robove v sliki. Prva metoda uporablja za barvanje nevronsko mrežo \cite{Cheng2015}, ki pa vsebuje zgolj polnopovezane nivoje, druga pa za barvanje uporabi metodo naključnih gozdov (ang. {\em random forest}) \cite{Deshpande2015}. 

Novejši pristopi barvanja črnobelih slik tipično temeljijo na konvolucijskih nevronskih mrežah, ki imajo to lastnost, da v vsakem nivoju same odkrijejo značilke, ki so pomembni. Prva tovrstna rešitev \cite{Dahl} gradi mrežo na podlagi  že zgrajene šestnajst-nivojske mreže VGG-16, ki so jo razvili na univerzi v Oxfordu \cite{Simonyan2014}. Rešitev uporablja evklidsko cenilno funkcijo in barvni prostor YUV. Slabost te rešitve je, da izhodne barvne slike niso dovolj nasičene. 

V zadnjem času predlagane rešitve popravijo problem nenasičenosti z uporabo softmax funkcije v zadnjem nivoju nevronske mreže, kar pomeni, da so problem spremenili iz regresijskega v klasifikacijskega.  
Zang in sod. \cite{zhang2016colorful} uporabijo konvolucijsko nevronsko mrežo z več nivoji in aktivacijskimi funkcijami ReLU. Posebnost te mreže je cenilna funkcija. Uporablja križno entropijo, ki pa je v tem primeru izvedena na primerjavi barv posameznih delov slike glede na barvni prostor, ki je kvantiziran. Napake so pomnožene z utežjo, ki določa pogostost barve. Bolj redke barve so obtežene tako, da prispevajo večji delež k napaki, ki jo izračuna cenilna funkcija. S tem so avtorji izboljšali rezultate, tako da se bolj pogosto pojavljajo tudi močnejši odtenki (tisti z višjimi vrednostmi v prostoru \textit{a*b*}, ki so bili prej redkeje zastopani zaradi bolj pogostega pojavljanja nežnejših barv v slikah (barve bližje vrednostim $(0, 0)$ v \textit{a*b*} prostoru. Pogostost je bila izračunana z analizo vseh slik v podatkovni zbirki Imagenet \cite{ILSVRC15}.  Uporabljajo barvni prostor L*a*b. 
Larsson in sod. \cite{larsson2016learning} za osnovo uporabijo mrežo VGG-16, iz katere vzamejo napovedi vsakega nivoja, ki jih združijo v enotno matriko. Sledi še en polno-povezan nivo na nivoju točk v sliki. Rezultat klasifikacije je histogram za vsako točko v sliki (histogram z verjetnostmi). Uporabljajo barvni prostor HSV. Cenilna funkcija, ki jo uporabljajo je KL-divergenca, ki primerja izhodni histogram z v histogram pretvorjeno originalno sliko. 
Iizuka in sod. \cite{Iizuka2016} uporabijo nevronsko mrežo sestavljeno iz dveh delov. Prvi del poskrbi za napovedovanje vsebine slike, ki se potem združi z drugim delom in izboljša natančnost barvanja. Uporabili so križno entropijo (ang. {\em cross entropy}) v kombinaciji s cenilno funkcijo \textit{povprečna kvadratna napaka} (ang. {\em Mean squared error}) in barvni prostor L*a*b. Za razliko od prejšnjih dveh metod zadnja ne napoveduje histograma na podlagi kvantiziranega prostora ampak direktno $a*$ in $b*$ vrednost, kar pomeni, da ne uporablja klasifikacije ampak regresijo.

\section{Globoke nevronske mreže}
\label{se:globoke}

Globoke nevronske mreže so algoritmi, ki so zgrajeni na podlagi opazovanja strukture možganov. Veliko se uporabljajo za klasifikacijo, regresijo, gručenje in napovedovalno analizo. Predvsem se uporabljajo na področju slik, kjer je zelo pomembno prepoznavanje objektov in obrazov, razvrščanje slik v skupine glede na podobnost, prepoznavanje gest in barvanje slik \cite{Gibson}.


Nevronska mreža je v osnovi funkcija $f(x)$, ki preslika vhod $x$ v izhod $y$. Med postopkom učenja je ta funkcija optimizirana tako, da najde najboljšo povezavo med vhodnimi in izhodnimi podatki \cite{Gibson}. Nevronske mreže so ime za strukturo, ki je sestavljena iz več nivojev. Nivoje si lahko predstavljamo kot vrsto vozlišč, ki se odzovejo v primeru da je vzburjenje na njih zadovoljivo - odvisno od aktivacijske funkcije. Struktura vozlišča in nivojev je predstavljena na sliki \ref{im:nn-structure}. Vozlišče pomnoži vsak vhod s trenutnimi vrednostmi uteži, vrednosti sešteje in moč aktivacije izračuna s pomočjo tako imenovane aktivacijske funkcije, ki tvori izhod vozlišča. Aktivacijski funkciji rečemo tudi neliearnot, saj poskrbi za to, da nevronska mreža ni le linearna funkcija. \cite{Karpathy2016a} Uteži se skozi postopek učenja spreminjajo in s tem določijo aktivacijo vozlišča. 

\begin{figure}
\begin{center}
\centering
\includegraphics[width=7cm]{node_structure}
\includegraphics[width=4cm]{nn_structure}
\end{center}
\caption{Leva slika prikazuje zgradbo enega vozlišča, ki ima zasnovo podobno nevronom v možganih, desna pa zgradbo več nivojske nevronske mreže. Iz: Introduction to Deep Neural Networks url{https://deeplearning4j.org/neuralnet-overview} in Neural Networks, url{http://docs.opencv.org/2.4/modules/ml/doc/neural\_networks.html} (dostopano: 21. junij 2017)}
\label{im:nn-structure}
\end{figure}

Nivojem v nevronskih mrežah, ki se nahajajo med vhodnim in izhodnim nivojem rečemo \textit{skriti nivoji} (angl. \textit{hidden layers}) \cite{Karpathy2016a}. Tradicionalni algoritmi na področju strojnega učenja so sestavljeni iz vhodnega, izhodnega nivoja in enega skritega nivoja, \textit{globoka nevronska mreža} (ang. \textit{deep neural network}) pa ima vsaj dva skrita nivoja \cite{collobert2008unified}, večinoma pa mnogo več. Vsak nivo globoke nevronske mreže prepozna določen lastnosti vhodnih podatkov. Nivoji, ki se nahajajo globje lahko prepoznajo bolj kompleksne lastnosti podatkov, saj na vhodu, dobijo lastnosti oziroma aktivacije nivoja pred njim. 

Da nevronska mreža daje zadovoljive rezultate je potrebno utežem določiti prave vrednosti. To naredimo s postopkom učenja. Vsaka nevronska mreža ima cenilno funkcijo (ang. loss function), ki pove kako dobre rezultate na testnih podatkih nevronska mreža daje trenutno. V postopku učenja zmanjšujemo vrednost cenilne funkcije z enim od algoritmov optimizacije. 

\subsection{Konvolucijske nevronske mreže}

Ker bi bilo na primeru slik pri uporabi klasičnih nevronskih mrež hitro preveč parametrov, kar bi poleg podaljšanja časa učenja povzročilo tudi prekomerno prilagajanje (ang. overfitting), uporabljamo za take primere konvolucijske nevronske mreže. Te so zelo podobne običajnim nevronskim mrežam. Sestavljene so iz nevronov, ki imajo svoje uteži in bias, ki so učljivi. Operacije znotraj nevrona so podobne tistim pri običajnih nevronskih mrežah, le da so prilagojene pričakovanim vhodnim podatkom - slikam. Vhod v vsak nivo nevronske mreže je torej matrika z obliko \textit{širina x višina x globina} \cite{Karpathy2016}. Te so v osnovi sestavljene iz treh vrst nivojev:

\begin{itemize}

\item \textbf{Konvolucijski nivo} je glavni gradnik konvolucijske nevronske mreže. Parametri tega nivoja so sestavljeni iz majhnih konvolucijskih jeder, ki pokrivajo majhno polje v širino in višino obenem pa pokrivajo celotni nivo v globino. Med prehodom po nevronski mreži izvedemo konvolucijo po celotni višini in širi vhodne matrike, po globini pa se te izhode teh konvolucij sešteje enako kot pri običajni nevronski mreži. Izhod konvolucije z enim setom jeder je dvodimenzionalna matrika. \cite{lecun1995convolutional} 

\item \textbf{Pooling nivo} je namenjen pod-vzorčenju (ang. downsampling) na določenem nivoju. S tem zmanjšamo število parametrov, kar vpliva zmanjšanje računske zahtevnosti in prekomernega prilagajanja. Deluje na principu, da je točna lokacija značilke manj pomembna kot približna lokacija glede na ostale značilke. \cite{Krizhevsky2012} 

\item \textbf{Polno povezni nivo} je nivo enak skritim nivojem pri klasični nevronski mreži. Uporabi se za zadnjih nekaj nivojev pri konvolucijski nevronski mreži. 

\end{itemize}

%----------------------------------------------------------------
% Poglavje (Chapter) 3: Pregled področja
%----------------------------------------------------------------

\chapter{Barvanje črno-belih slik z globokimi nevronskimi mrežami}

\section{Arhitekture}
\label{ch:arhitekture}

V grobem smo v okviru magistrske naloge implementirali 4 arhitekture nevronskih mrež, kasneje smo te arhitekture kombinirali z različnimi cenilnimi funkcijami, pristopi (regresijski ali klasifikacijski) in načini napovedovanja (napovedovanje po delih ali na celi sliki).

\subsection{Plitva arhitektura z globalno mrežo}
\label{ch:plitva}

Ta arhitektura je sestavljena iz dveh delov, ki se kasneje združita v enotno mrežo. Glavni del predstavlja zaporedje konvolucijskih nivojev, ki na vhodu vzamejo sivinsko sliko, izhod pa je obarvana slika. Po osmih kovolucijskih nivojih se mreža združi z tako imenovano globalno mrežo, ki napoveduje objekt, ki ga slika predstavlja. Za globalno mrežo smo vzeli že naučeno mrežo VGG-16 \cite{Simonyan2014}, ki smo ji odvzeli zadnji polno-povezani nivo in ji dodali nov polno-povezani nivo z izhodnim tenzorjem dolžine 256. Ker je ta mreža namenjena sprejemu barvnih RGB slik smo vhod prilagodili tako, da sprejme sivinsko sliko na vseh treh kanalih. Arhitektura nevronske mreže je predstavljena na sliki \ref{im:arh1} in v tabeli \ref{tab:arh1} v prilogi.

Na tem mestu bi bilo smiselno opisati še kako poteka združevanje dveh mrež. Vhod v element za združevanje sta tenzorja velikosti $w/8 x h/8 x 256$ iz glavne mreže in enodimenzionalni tenzor velikosti $256$ iz globalne mreže. Pri tem $w$ in $h$ predstavljata širino in višino vhodne slike v mrežo. Pri združevanju vsakemu elementu širine in višine prvega tenzorja pridružimo tenzor globalne mreže, kot prikazuje slika \ref{im:fusion}. Tako na izhodu dobimo tenzor velikosti $\frac{w}{8} \times \frac{h}{8} \times 512$. 
 
\begin{figure}
\begin{center}
\centering
\includegraphics[width=12cm]{arh1}
\end{center}
\caption{Slika prikazuje velikosti tenzorjev skozi plitvo arhitekturo z globalno nevronsko mrežo. $w$ in $h$ predstavljata širino in višino vhodne slike. Podrobnosti nivoja združitev so predstavljene na sliki \ref{im:fusion}, nivo izhodne slike ni natančneje označen, saj se razlikuje v različnih implementacijah, ki bodo podrobneje opisane v poglavju ??. }
\label{im:arh1}
\end{figure}

\begin{figure}
\begin{center}
\centering
\includegraphics[width=8cm]{fusion}
\end{center}
\caption{Prikaz delovanje nivoja združevanja glavne nevronske mreže z globalno nevronsko mrežo. K izhodu glavne nevronske mreže dodamo tenzor iz globalne mreže, tako da ga priključimo k vsem prostorskim lokacija kot dodatnih 256 kanalov. }
\label{im:fusion}
\end{figure}

% l2 regularizacija citation \cite{mackay1992practical}

\subsection{Globja arhitektura z globalno mrežo}
\label{ch:globjaz}

Ta arhitektura ima v osnovi enako zasnovo, kot v poglavju \ref{ch:plitva} opisana arhitektura. Razlika se pojavi pri globini glavne mreže. Ta ima namreč mnogo več nivojev kot lahko vidite na sliki \ref{im:arh2} in tabeli \ref{tab:arh2} v prilogi. Za razliko od arhitekture opisane v poglavju \ref{ch:plitva} ta za zmanjševanje prostorskih (ang. {\em spatial}) dimenzij uporablja maksimalno združevanje (ang. {\em max pooling}) in za povečevanje le teh v zadnjih nivojih uporablja transponirano konvolucijo (ang. {\em transpose convolution}) \cite{Dumoulin2016}. Združevanja glavne in globalne mreže se izvede na način opisan v poglavju \ref{ch:plitva}.

Ta arhitektura prinaša še eno spremembo. To so tako imenovane rezidualne povezave, ki so bile prvič uporabljene v nevronski mreži ResNet \cite{Wu2017}, ki je leta 2015 zmagala na tekmovanju ImageNet \cite{ILSVRC15}. Te povezave so na sliki \ref{im:arh2} označene s puščicami nad nevronsko mrežo in predstavljajo povezavo, ki na mestu kamor kaže puščica, združi trenutni tenzor z tenzorjem izračunanim pred dvema nivojema. Operacija združevanja je seštevanje.  


\begin{figure}
\begin{center}
\centering
\includegraphics[width=12cm]{arh2}
\end{center}
\caption{Slika prikazuje velikosti tenzorjev skozi globjo arhitekturo z globalno nevronsko mrežo. $w$ in $h$ predstavljata širino in višino vhodne slike. Podrobnosti nivoja združitev so predstavljene na sliki \ref{im:fusion}, nivo izhodne slike ni natančneje označen, saj se razlikuje v različnih implementacijah, ki bodo podrobneje opisane v poglavju ??. }
\label{im:arh2}
\end{figure}

\subsection{Globja arhitektura brez globalne mreže}

Ta arhitektura je enaka tisti opisani v poglavju \label{globjaz} in prikazani na sliki \ref{im:arh2} v glavnem delu in se razlikuje po tem, da nima globalne mreže. Torej nima mreže, ki se pridruži v nivoju združitve, zaradi tega smo tudi ta nivo izpustili. Mreža za vhod vzame črno-belo sliko z enim kanalom in izračuna barvno sliko na izhodu. Ta arhitektura je bila načrtovana z namenom, da se preveri če ima globalna mreža prisotna v arhitekturah predstavljenih v poglavjih \ref{ch:globjaz} in \ref{ch:plitva} kakšen vpliv na rezultate.

\subsection{Dopolnjena VGG-16 arhitektura}

Arhitektura je zgrajena tako, da za vrh mreže uporabimo mrežo VGG-1 6 \cite{Simonyan2014}, kateri smo odstranili vse polno povezane nivoje. Arhitektura je narejena tako, da na vhodu sprejme črno-belo sliko, ki se potem prilagodi na vhod mreže VGG-16. Tenzor, ki ga vrne zadnji konvolucijski nivo omenjene mreže podam na vhod mreže, ki je prikazana na sliki \ref{im:arh4} in podrobno opisana v tabeli \ref{tab:arh4} v prilogi.

\begin{figure}
\begin{center}
\centering
\includegraphics[width=12cm]{arh4}
\end{center}
\caption{Slika prikazuje velikosti tenzorjev skozi dopolnjeno VGG-16 arhitekturo. $w$ in $h$ predstavljata širino in višino vhodne slike. Nivo izhodne slike ni natančneje označen, saj se razlikuje v različnih implementacijah, ki bodo podrobneje opisane v poglavju ??. }
\label{im:arh4}
\end{figure}

\section{Pristopi z regresijo}

V tem poglavju bomo prestavili regresijske metode, ki smo jih uporabili. Te se imenujejo tako, saj pri napovedovanju barve direktno napovejo vrednosti $a*$ in $b*$ barvne komponente v prostoru \textit{CIE L*a*b*}. Tu mreža predstavlja regresijsko funkcijo $y = f(x)$ za vsako točko na slike, ki na vhod dobi točko sivinske slike $x$, izhod pa je kar vrednost $y$, ki predstavlja določeno barvo v našem primeru sta to dve vrednosti $a*$ in $b*$.

Na sliki \ref{im:reg-scheme} je prikazan postopek delovanja, ki je skupen vsem regresijskim metodam opisanim v nadaljevanju. Da dobimo barvno sliko moramo izhod iz mreže, ki predstavlja barvne komponente združiti s sivinsko.


\begin{figure}[hbt]
\begin{center}
\centering
\includegraphics[width=12cm]{regresija-shema}
\end{center}
\caption{Shematski prikaz delovanja regresijske metode, ki na vhod prejme črno-belo sliko, s pomočjo nevronske mreže izračuna barvni komponenti $a*$ in $b*$ barvnega prostora \textit{CIE L*a*b*} ter to združi s sivinsko sliko $L*$, da dobi obarvano sliko. }
\label{im:reg-scheme}
\end{figure}

\subsection{Pristopi na delih slik}
\label{ch:parts-im}

V to skupino lahko uvrstimo tri metode, ki imajo skupno to, da smo barvanje izvajali na majhnih delih slik. Ta princip smo razvili z opazovanjem delovanja človeškega zaznavnega sistema, ki se bi lotil barvanja po delih, na sliki bi zaznal objekte ločeno barval. Na primer najprej vodo, nato gozd in kasneje še nebo. 

Sliko smo preden smo jo podali nevronski mreži razdelili na koščke velikosti $32 \times 32$. Pri tem sta se sosednja koščka prekrivala za $16$ slikovnih točk. 
V arhitekturah, kjer je bila prisotna ločena globalna mreža, je ta še vedno na vhodu prejela celotno sliko, s katero smo pridobili globalni koncept slike. Dele slik smo kasneje sestavili z metodo prekrivanja, tako da so imele vrednosti točk pri robu manjši vpliv kot tiste pri sredini. Vpliv barvne točke se je izračunal po enačbi \ref{eq:1}, kjer $x$ predstavlja vrednost slikovne točke, $d$ predstavlja oddaljenost od središča v številu slikovnih točk. Enačba se ločeno uporablja v vertikalni in horizontalni smeri. 

\begin{equation}
y = \frac{d}{16} * x
\label{eq:1}
\end{equation}

Z takim načinom dela pričakujemo pohitritev učenja, saj menimo, da je že del slike dovolj da se mreža nauči celotne teksture objekta. Na primer, da se naučimo barvati vodo ne potrebujemo celotnega območja vode na sliki, ki včasih lahko prekriva tudi pol ali več slike, ampak le en del. Z učenjem mreže na manjših vhodnih tenzorjih, kar dosežemo z učenjem po delih, se čas, ki ga mreža porabi za učenje ene serije (ang. {\em batcha}) podatkov zmanjša. 

V tabeli \ref{tab:methods-parts} so predstavljene podrobnosti vsake od metod barvanja po delih.

\begin{table}[hbt]
\caption{Regresijski pristopi po delih, njihove arhitekture, ki so podrobneje opisane v poglavju \ref{ch:arhitekture} in cenilne funkcije uporabljene za učenje. $MSE$ je povprečna kvadratna napaka (ang. {\em mean squared error}).}
\begin{center}
    \begin{tabular}{l|cc}
	Ime metode & Arhitektura & Cenilna funkcija \\
	\hline
	Reg. po delih & Globja arh. z glob. mr. & MSE \\
	\hspace{0.5em} - brez softmax & Globja arh. z glob. mr. & MSE \\
	\hspace{0.5em} - brez globalne mreže & Globja arh. brez glob. mr. & MSE \\
    \end{tabular}
\end{center}
\label{tab:methods-parts}
\end{table}

\subsection{Pristopi na delih slik}

Za primerjavo točnosti metod na delih slik s tistimi na celih slikah. Smo dve metodi opisane v poglavju \ref{ch:parts-im} pretvorili v metode za barvanje na celih slikah. Tej smo dodali še eno metodo, saj zaradi večkratnega pomanjšanja prostorskih dimenzij znotraj arhitekture ne more biti realizirana na manjših delih slik.

V tabeli \ref{tab:methods-whole} so podrobno predstavljene lastnosti teh metod. 

\begin{table}[hbt]
\caption{Regresijski pristopi na celih slikah, njihove arhitekture, ki so podrobneje opisane v poglavju \ref{ch:arhitekture} in cenilne funkcije uporabljene za učenje. $MSE$ je povprečna kvadratna napaka (ang. {\em mean squared error}).}
\begin{center}
\begin{tabular}{l|cc}
Ime metode & Arhitektura & Cenilna funkcija \\
\hline
Reg. cela slika & Globja arh. z glob. mr. & MSE \\
\hspace{0.5em} - brez globalne mreže & Globja arh. brez glob. mr. & MSE \\
Reg. cela slika VGG & Dop. VGG-16 arh. & MSE \\
\end{tabular}
\end{center}
\label{tab:methods-whole}
\end{table}

\section{Pristopi s klasifikacijo}

\section{Postopek učenja}

\begin{figure}
\begin{center}
\centering
\includegraphics[width=11cm]{histograms-100}
\end{center}
\caption{Prikaz padanja napake modela pri učenju. Za vsak prehod preko vseh podatkov (ang. {\em epoch}) je prikazana napaka na množici za treniranje in testni množici. }
\label{im:histograms-100}
\end{figure}

Tukaj bi dali tudi slike po nivojih - kaj so znacilke posameznega nivoja

%----------------------------------------------------------------
% Poglavje (Chapter) 4: Podatki
%----------------------------------------------------------------

\chapter{Podatki}

%----------------------------------------------------------------
% Poglavje (Chapter) 5: Rezulatati in diskusija
%----------------------------------------------------------------

\chapter{Rezultati in diskusija}

\section{Primerjava metod na manjši učni množici}

\begin{table}
\caption{Napake izračunane na testni podatkovni zbirki.}
\begin{center}
    \begin{tabular}{l|ccc}
        Metoda & RMSE & PSNR \\
        \hline
        Zhang in sod. & 15.004 & 22.252 \\
        Iizuka in sod. & 12.941 & 23.439 \\
        Dahl & 13.936 & 22.551 \\
        \hline
        Reg. po delih & 13.216 & 23.199 \\
        \hspace{0.5em} - brez softmax & 13.206 & 23.183 \\
        \hspace{0.5em} - brez globalne mreže & 13.767 & 22.840 \\
        Reg. celotna slika & 13.007 & 23.434 \\
        \hspace{0.5em} - brez globalne mreže & 13.334 & 23.068 \\
        Reg. celotna slika VGG & 13.387 & 23.131 \\
        \hline
        Klas. brez uteži - arih. 1 & 14.336 & 22.738 \\
        Klas. brez uteži - arih. 2 & 15.086 & 22.380 \\
        Klas. z utežmi - arih. 1 & 14.573 & 22.610 \\         
        Klas. z utežmi - arih. 2 & 15.137 & 22.395 \\ 
    \end{tabular}
\end{center}
\label{tab:napake-100}
\end{table}

\begin{figure}
\begin{center}
\centering
\fbox{\includegraphics[width=11cm]{methods_mds}}
\end{center}
\caption{Primerjava metod v prostoru MDS kaže sorodnosti med metodami na način napovedovanja barve (klasifikacija proti regresiji) in glede na arhitekturo mreže. Mreže, ki uporabljajo mrežo VGG za napovedovanje objekta v sliki so bližje skupaj in modeli brez VGG mreže so bližje skupaj.  }
\label{im:methods-mds}
\end{figure}

\begin{figure}
\begin{center}
\centering
\includegraphics[width=6cm]{ranks_dahl_arh2}
\includegraphics[width=6cm]{rank_arh2_arh2}
\end{center}
\caption{Graf prikazuje rangiranje slik glede na napako \textit{RMSE} pri dveh različnih metodah. $X$ os predstavlja rang pri prvi metodi, $Y$ pa rang pri drugi metodi. Prva slika prikazuje primerjave rangov Dahlove metode in klasifikacijske metode z arhitekture 2. Druga metoda prikazuje range pri dveh klasifikacijskih metodah z istimi arhitekturami.}
\label{im:ranks-between-methods}
\end{figure}

\begin{figure}
\begin{center}
\centering
\fbox{\includegraphics[width=11cm]{images_mds}}
\end{center}
\caption{Razporeditev slik v prostoru MDS, ki zajema 100 sli, ki kjer natančnosti najbolj odstopajo pri različnih metodah. V prostoru so točke podobnih slik bliže skupaj. Dve taki podobni skupini slik sta prikazani ob robu.   }
\label{im:images-mds}
\end{figure}

\section{Primerjava metod na večji učni množici}

Tukaj bi primerjali metode, ki bi bile naučene na več slikah, tako bi pridobili tudi boljša barvanja za pokazat izboljševanje barvanja glede na epoche. Primerjavo bi izvedli na manj manj metodah. 

\section{Barvanje večjih slik}


%----------------------------------------------------------------
% Poglavje (Chapter) 6: Zaključek
%----------------------------------------------------------------

\chapter{Zaključek}


%----------------------------------------------------------------
% Poglavje: Priloge
%----------------------------------------------------------------

\appendix
%\addcontentsline{toc}{chapter}{Razširjeni povzetek}
\chapter{Spearmanova korelacija rangov med metodami}

\begin{table}
\caption{Spearmanova korelacija med metodami. }
\begin{center}
\begin{tabular}{l|ccccccccccccc}
          &Zang&Iizuka&Dahl      &Reg. po de&Reg. po de&Reg. po de&Reg. celot&Reg. celot&Reg. celot&Klas. brez&Klas. brez&Klas. z ut&Klas. z ut \\
\hline
Zang in so&1.0000    &0.8607    &0.8688    &0.8637    &0.8407    &0.8898    &0.8779    &0.8804    &0.8969    &0.9092    &0.9409    &0.9242    &0.9023     \\
Iizuka in &0.8607    &1.0000    &0.8936    &0.9454    &0.9420    &0.9015    &0.9472    &0.9206    &0.9398    &0.9012    &0.8519    &0.8535    &0.8889     \\
Dahl      &0.8688    &0.8936    &1.0000    &0.9008    &0.9058    &0.9816    &0.8889    &0.9518    &0.9196    &0.8636    &0.8861    &0.8722    &0.8431     \\
Reg. po de&0.8637    &0.9454    &0.9008    &1.0000    &0.9440    &0.9096    &0.9392    &0.9149    &0.9309    &0.9004    &0.8622    &0.8578    &0.8861     \\
Reg. po de&0.8407    &0.9420    &0.9058    &0.9440    &1.0000    &0.9120    &0.9313    &0.9194    &0.9211    &0.8795    &0.8434    &0.8390    &0.8640     \\
Reg. po de&0.8898    &0.9015    &0.9816    &0.9096    &0.9120    &1.0000    &0.9005    &0.9642    &0.9263    &0.8784    &0.8979    &0.8817    &0.8582     \\
Reg. celot&0.8779    &0.9472    &0.8889    &0.9392    &0.9313    &0.9005    &1.0000    &0.9140    &0.9334    &0.9030    &0.8657    &0.8632    &0.8904     \\
Reg. celot&0.8804    &0.9206    &0.9518    &0.9149    &0.9194    &0.9642    &0.9140    &1.0000    &0.9371    &0.8759    &0.8650    &0.8558    &0.8544     \\
Reg. celot&0.8969    &0.9398    &0.9196    &0.9309    &0.9211    &0.9263    &0.9334    &0.9371    &1.0000    &0.9065    &0.8881    &0.8831    &0.8937     \\
Klas. brez&0.9092    &0.9012    &0.8636    &0.9004    &0.8795    &0.8784    &0.9030    &0.8759    &0.9065    &1.0000    &0.9209    &0.9240    &0.9489     \\
Klas. brez&0.9409    &0.8519    &0.8861    &0.8622    &0.8434    &0.8979    &0.8657    &0.8650    &0.8881    &0.9209    &1.0000    &0.9813    &0.9126     \\
Klas. z ut&0.9242    &0.8535    &0.8722    &0.8578    &0.8390    &0.8817    &0.8632    &0.8558    &0.8831    &0.9240    &0.9813    &1.0000    &0.9230     \\
Klas. z ut&0.9023    &0.8889    &0.8431    &0.8861    &0.8640    &0.8582    &0.8904    &0.8544    &0.8937    &0.9489    &0.9126    &0.9230    &1.0000     \\
\end{tabular}
\end{center}
\end{table}

\chapter{Podrobnosti arhitektur}

\begin{longtable}[h]{l|ccccc}
\caption{Tabela prikazuje nivoje plitve arhitekture z globalno mrežo in njihove parametre. $K$ predstavlja število kanalov izhoda nevronske mreže, $J$ pove velikost jedra, $Ko$ je korak (ang. {\em stride}) uporabljen na nivoju in $Akt$ predstavlja aktivacijo po vsakem nivoju. Zadnji konvolucijski nivo nima definiranega števili izhodnih kanalov, saj je to odvisno od pristopa, ki smo ga uporabili. Pri nadvzorčenju smo vedno nadvzorčili s faktorjem 2, kar pomeni, da ima tensor, ki predstavlja izhod po širini in višini dvakratno velikost. }\\

		Nivo & K & J & K & Akt \\
		\hline
		Vhod & 1 & - & - & - \\
		2D konvolucija & 64 & 3 & 2 & Relu\\
		2D konvolucija & 128 & 3 & 1 & Relu \\
		2D konvolucija & 128 & 3 & 2 & Relu \\
		2D konvolucija & 256 & 3 & 1 & Relu\\		
		2D konvolucija & 256 & 3 & 2 & Relu\\
		2D konvolucija & 512 & 3 & 1 & Relu\\
		2D konvolucija & 512 & 3 & 1 & Relu\\
		2D konvolucija & 256 & 3 & 1 & Relu\\
		Združitev z globalno mrežo & 512 & - & - & - \\

		2D konvolucija & 256 & 3 & 1 & Relu\\
		Nadvzorčenje & 256 & - & - & -\\
		2D konvolucija & 256 & 3 & 1 & Relu\\
		2D konvolucija & 256 & 3 & 1 & Relu\\
		Nadvzorčenje & 256 & - & - & -\\
		2D konvolucija &  & 3 & 1 & Relu \\
        

\label{tab:arh1}
\end{longtable}

\begin{longtable}[h]{ll|ccccc}
\caption{Tabela prikazuje nivoje globje arhitekture z globalno mrežo in njihove parametre. $K$ predstavlja število kanalov izhoda nevronske mreže, $J$ pove velikost jedra, $Ko$ je korak (ang. {\em stride}) uporabljen na nivoju, $Akt$ predstavlja aktivacijo po vsakem nivoju in $Reg$ določa stopnjo regularizacije. V vseh nivojih uporabljamo \textit{L2 regulrizacijo} \cite{mackay1992practical}. Zadnji konvolucijski nivo nima definiranega števili izhodnih kanalov, saj je to odvisno od pristopa, ki smo ga uporabili. }\\

Zap. št. & Nivo & K & J & Ko & Akt & Reg\\
\hline
0 & Vhod & 1 & - & - & - & - \\
1 & 2D konvolucija & 64 & 3 & 1 & Relu & 0.01\\

2 & Maks. združevanje & 64 & 2 & 2 & - & - \\
3 & 2D konvolucija & 128 & 3 & 1 & Relu & 0.01\\
4 & 2D konvolucija & 128 & 3 & 1 & Relu & 0.01\\
5 & 2D konvolucija & 128 & 3 & 1 & Relu & 0.01\\
6 & Vsota z 3 & 128 & - & - & - & -\\
7 & 2D konvolucija & 128 & 3 & 1 & Relu & 0.01\\

8 & Maks. združevanje & 128 & 2 & 2 & - & - \\
9 & 2D konvolucija & 256 & 3 & 1 & Relu & 0.01\\
10 & 2D konvolucija & 256 & 3 & 1 & Relu & 0.01\\
11 & 2D konvolucija & 256 & 3 & 1 & Relu & 0.01\\
12 & Vsota z 9 & 256 & - & - & - & -\\
13 & 2D konvolucija & 256 & 3 & 1 & Relu & 0.01\\
		
14 & Maks. združevanje & 265 & 2 & 2 & - & - \\
15 & 2D konvolucija & 512 & 3 & 1 & Relu & 0.01\\
16 & 2D konvolucija & 512 & 3 & 1 & Relu & 0.01\\
17 & 2D konvolucija & 512 & 3 & 1 & Relu & 0.01\\
18 & Vsota z 15 & 512 & - & - & - & -\\
19 & 2D konvolucija & 512 & 3 & 1 & Relu & 0.01\\
20 & 2D konvolucija & 256 & 3 & 1 & Relu & 0.01\\

21 & Združitev z globalno mrežo & 512 & - & - & - & - \\

22 & 2D konvolucija & 128 & 3 & 1 & Relu & 0.01\\
23 & 2D transponirana kovnolucija & 64 & 3 & 2 & Relu & 0.01\\
24 & 2D kovnolucija & 64 & 3 & 1 & Relu & 0.01 \\
25 & 2D kovnolucija & 64 & 3 & 1 & Relu & 0.01 \\
		
26 & 2D transponirana kovnolucija & 64 & 3 & 2 & Relu & 0.01\\
27 & 2D kovnolucija & 32 & 3 & 1 & Relu & 0.01 \\
28 & 2D kovnolucija &  & 3 & 1 & Relu & 0.01 \\

\label{tab:arh2}
\end{longtable}

\begin{longtable}[h]{ll|ccccc}
\caption{Tabela prikazuje nivoje dopolnjene VGG mreže in njihove parametre. $K$ predstavlja število kanalov izhoda nevronske mreže, $J$ pove velikost jedra, $Ko$ je korak (ang. {\em stride}) uporabljen na nivoju, $Akt$ predstavlja aktivacijo po vsakem nivoju in $Reg$ določa stopnjo regularizacije. V vseh nivojih uporabljamo \textit{L2 regulrizacijo} \cite{mackay1992practical}. Zadnji konvolucijski nivo nima definiranega števili izhodnih kanalov, saj je to odvisno od pristopa, ki smo ga uporabili. Vsako nadvzorčenje prostorske dimenzije poveča za 2 krat.  }\\

Zap. št. & Nivo & K & J & Ko & Akt & Reg\\
\hline
0 & Vhod & 1 & - & - & - & - \\
1 & VGG-16 mreža & 512 & - & - & - & -\\

2 & Nadvzorčenje & 512 & - & - & - & - \\
3 & 2D konvolucja & 256 & 3 & 1 & Relu & 0.01 \\
4 & 2D konvolucja & 256 & 3 & 1 & Relu & 0.01 \\

5 & Nadvzorčenje & 256 & - & - & - & - \\
6 & 2D konvolucja & 128 & 3 & 1 & Relu & 0.01 \\
7 & 2D konvolucja & 128 & 3 & 1 & Relu & 0.01 \\

8 & Nadvzorčenje & 128 & - & - & - & - \\
9 & 2D konvolucja & 64 & 3 & 1 & Relu & 0.01 \\
10 & 2D konvolucja & 164 & 3 & 1 & Relu & 0.01 \\

11 & Nadvzorčenje & 64 & - & - & - & - \\
12 & 2D konvolucja & 32 & 3 & 1 & Relu & 0.01 \\
13 & 2D konvolucja &  & 3 & 1 & Relu & 0.01 \\

\label{tab:arh4}
\end{longtable}




%----------------------------------------------------------------
% SLO: bibliografija
% ENG: bibliography
%----------------------------------------------------------------
\bibliographystyle{elsarticle-num}

%----------------------------------------------------------------
% SLO: odkomentiraj za uporabo zunanje datoteke .bib (ne pozabi je potem prevesti!)
% ENG: uncomment to use .bib file (don't forget to compile it!)
%----------------------------------------------------------------
\bibliography{bibliography}

%----------------------------------------------------------------
% SLO: zakomentiraj spodnji del, če uporabljaš zunanjo .bib datoteko
% ENG: comment the part below if using the .bib file
%----------------------------------------------------------------



\end{document}
